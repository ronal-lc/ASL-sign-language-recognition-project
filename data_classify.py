"""
ASL Hand Sign Classifier Training Script

This script trains a neural network to classify American Sign Language (A-Z + STOP) hand signs
using landmark data extracted from images. The model is saved in Keras format for later use.

Usage:
    - Ensure 'data_signs.pickle' exists (generated by the dataset creation script).
    - Run this script to train and save the model as 'model.keras'.

Dependencies:
    - scikit-learn
    - tensorflow
    - pickle

Author: @ronal-lc
"""

import pickle
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Input # Dropout is imported but not used.
from tensorflow.keras.optimizers import Adam
import os 
import numpy as np
import json # Import json for saving metrics


def train_model_main():
    """Main function to train the model."""
    print("INFO: Starting model training process.")
    
    # Check if data_signs.pickle exists
    pickle_file_path = 'data_signs.pickle'
    if not os.path.exists(pickle_file_path):
        print(f"CRITICAL: Error: Dataset file '{pickle_file_path}' not found.")
        print("CRITICAL: Please generate the dataset by running 'create_dataset.py' first.")
        return

    # Load dataset
    print(f"INFO: Loading dataset from '{pickle_file_path}'.")
    try:
        with open(pickle_file_path, 'rb') as f:
            dataset = pickle.load(f)
        print("INFO: Dataset loaded successfully.")
    except Exception as e:
        print(f"ERROR: Error loading '{pickle_file_path}': {e}")
        return
    # This line was duplicated in the original provided code, removing one.
    # dataset = pickle.load(f) 


    X = dataset.get('data')
    y = dataset.get('labels')

    if X is None or y is None:
        print("ERROR: 'data' or 'labels' key not found in dataset file.")
        return
    
    if not isinstance(X, np.ndarray) or not isinstance(y, np.ndarray):
        print("ERROR: Data or labels in dataset file are not numpy arrays.")
        return

    if len(X) == 0: # len(y) would also be 0 if X is 0, given the check below
        print("ERROR: Data or labels are empty in dataset file.")
        return
        
    if len(X) != len(y):
        print(f"ERROR: Mismatch in number of samples between data ({len(X)}) and labels ({len(y)}).")
        return
    print(f"INFO: Dataset contains {len(X)} samples.")

    # Encode labels as integers
    if y.dtype == 'object' or isinstance(y[0], str): # Check if labels are strings that need encoding
        print("INFO: Attempting to encode string labels to integers.")
        label_encoder = LabelEncoder()
        try:
            y_encoded = label_encoder.fit_transform(y)
            print(f"INFO: Labels encoded successfully. Example - Original: {y[:3]}, Encoded: {y_encoded[:3]}")
        except Exception as e:
            print(f"ERROR: Error during label encoding: {e}")
            return
    else: # Labels are already encoded (assumed numeric)
        y_encoded = y 
        print(f"INFO: Labels appear to be already numerically encoded. Example: {y_encoded[:3]}")

    # Stratified train-test split
    print("INFO: Splitting data into training and testing sets.")
    try:
        X_train, X_test, y_train, y_test = train_test_split(
            X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
        )
        print(f"INFO: Data split successfully. Training samples: {len(X_train)}, Test samples: {len(X_test)}")
    except ValueError as e:
        print(f"WARNING: Error during stratified train_test_split: {e}. This might be due to insufficient samples for some classes for stratification.")
        print("INFO: Attempting train_test_split without stratification as a fallback.")
        try:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y_encoded, test_size=0.2, random_state=42 # No stratify
            )
            print(f"INFO: Fallback data split successful. Training samples: {len(X_train)}, Test samples: {len(X_test)}")
        except Exception as e_fallback:
            print(f"ERROR: Fallback train_test_split also failed: {e_fallback}")
            return
    except Exception as e_split_other:
         print(f"ERROR: An unexpected error occurred during data splitting: {e_split_other}")
         return


    # Neural network model definition
    num_classes = len(np.unique(y_encoded))
    if num_classes <= 1:
        print(f"ERROR: The dataset must contain at least 2 unique classes for classification. Found: {num_classes}")
        return
    print(f"INFO: Defining neural network model for {num_classes} classes.")
    
    if X_train.shape[1] == 0: # Should not happen if data loading was successful
        print("ERROR: Training data has no features (X_train.shape[1] is 0).")
        return

    model = Sequential([
        Input(shape=(X_train.shape[1],)), 
        Dense(128, activation='relu'),
        Dense(64, activation='relu'),
        Dense(num_classes, activation='softmax')
    ])
    print("INFO: Model defined successfully.")

    # Compile the model
    print("INFO: Compiling the model with Adam optimizer and sparse_categorical_crossentropy loss.")
    try:
        model.compile(
            optimizer=Adam(learning_rate=0.0005), 
            loss='sparse_categorical_crossentropy', 
            metrics=['accuracy'] 
        )
        print("INFO: Model compiled successfully.")
        model.summary() # Log model summary
    except Exception as e:
        print(f"ERROR: Error compiling the Keras model: {e}")
        return


    print("INFO: Starting model training...")
    try:
        history = model.fit(
            X_train, y_train,
            epochs=30,       
            batch_size=32,   
            validation_data=(X_test, y_test),
            verbose=1 # 0=silent, 1=progress bar, 2=one line per epoch. Keep 1 for user feedback.
        )
        print("INFO: Model training completed.")
        # Log some training history highlights
        if history and history.history:
            final_train_acc = history.history['accuracy'][-1]
            final_val_acc = history.history['val_accuracy'][-1]
            print(f"INFO: Final training accuracy: {final_train_acc:.4f}, Final validation accuracy: {final_val_acc:.4f}")
    except Exception as e: # Catch specific TF/Keras errors if possible, or general Exception
        print(f"ERROR: An error occurred during model training: {e}")
        # Potentially log more details from TF if available, e.g. tf.get_logger()
        return


    print("INFO: Evaluating model on the test set...")
    try:
        loss, accuracy = model.evaluate(X_test, y_test, verbose=1) 
        print(f"INFO: Model Test Accuracy: {accuracy * 100:.2f}%")
        print(f"INFO: Model Test Loss: {loss:.4f}")

        # Save metrics to a JSON file
        metrics_data = {"accuracy": accuracy, "loss": loss}
        metrics_file_path = 'training_metrics.json'
        print(f"INFO: Saving training metrics to '{metrics_file_path}'.")
        try:
            with open(metrics_file_path, 'w') as f_metrics:
                json.dump(metrics_data, f_metrics, indent=4)
            print(f"INFO: Metrics saved successfully to '{metrics_file_path}'.")
        except Exception as e_metrics:
            print(f"ERROR: Error saving metrics to '{metrics_file_path}': {e_metrics}")
            # Do not return here, as model saving might still be important

    except Exception as e:
        print(f"ERROR: An error occurred during model evaluation: {e}")
        # Consider if we should still attempt to save the model if evaluation fails
        # For now, we will return as the metrics won't be available.
        return

    # Save the trained model
    model_save_path = 'model.keras'
    print(f"INFO: Saving the trained model to '{model_save_path}'.")
    try:
        model.save(model_save_path)
        print(f"INFO: Model saved successfully as '{model_save_path}'")
    except Exception as e:
        print(f"ERROR: Error saving model to '{model_save_path}': {e}")
        # If model saving fails, this is a significant issue for the pipeline.
        # Depending on requirements, might want to indicate failure more strongly.

    print("INFO: Model training process finished.")

if __name__ == "__main__":
    # setup_logging(log_level=logging.INFO, log_file="data_classify.log") # Removed
    train_model_main()